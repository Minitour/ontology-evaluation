{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT Pre-training.ipynb","provenance":[],"authorship_tag":"ABX9TyMfFo2+gvuzaSvr7jnt1GTy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e559b60acbf344a2a9463a523017a6cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_502a141d3fb54ea28fc7b07c46e649e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_17f33352d96044f0a5112b4dacc3d6f1","IPY_MODEL_d948858390ec4160be053b537592b00e","IPY_MODEL_81a00a7bc12b410390fc6e9133296515"]}},"502a141d3fb54ea28fc7b07c46e649e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17f33352d96044f0a5112b4dacc3d6f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f559c1fe5ddf46cd9564b083b640b9ec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Skipping the first batches: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7af71da98db4379a667276ec435162e"}},"d948858390ec4160be053b537592b00e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c66fb6bc56b84cb3959a6b5bb5549668","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":11175,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":11175,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1c845597af746e0a6a9b5f195857912"}},"81a00a7bc12b410390fc6e9133296515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a441a6bdd4042a0b8b192bc394446b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 11175/11175 [00:53&lt;00:00, 216.71it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cf3e2824e454d49829c508931c2e22d"}},"f559c1fe5ddf46cd9564b083b640b9ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7af71da98db4379a667276ec435162e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c66fb6bc56b84cb3959a6b5bb5549668":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a1c845597af746e0a6a9b5f195857912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a441a6bdd4042a0b8b192bc394446b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cf3e2824e454d49829c508931c2e22d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","\n","[x.physical_device_desc for x in device_lib.list_local_devices() if x.device_type == 'GPU']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix0m0cgpNeit","executionInfo":{"status":"ok","timestamp":1648707812865,"user_tz":-180,"elapsed":10687,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}},"outputId":"586b7a04-a72a-48fd-980c-fd76f87245e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0',\n"," 'device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0']"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4939CoYaPX0e","executionInfo":{"status":"ok","timestamp":1649519757765,"user_tz":-180,"elapsed":254,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}},"outputId":"eacb9619-e32d-4d7f-dec1-06bab0d74540"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: GOOGLE_APPLICATION_CREDENTIALS=/home/key.json\n"]}],"source":["%env GOOGLE_APPLICATION_CREDENTIALS=/home/key.json"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install tokenizers"],"metadata":{"id":"N3NG3EOZTYgB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648328211403,"user_tz":-180,"elapsed":13199,"user":{"displayName":"Tony Zaitoun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIffENwXA3KxjXiTE-UI1We6xRItSJ19Jccnj1-sk=s64","userId":"11427402115843832412"}},"outputId":"8996f50c-1fb4-400a-ff82-992f42d67615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 58.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.11.6)\n"]}]},{"cell_type":"code","source":["import time\n","import argparse\n","import os\n","\n","from tokenizers import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","\n","from transformers import BertConfig, BertForMaskedLM\n","from transformers import RobertaTokenizer\n","from transformers import DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm"],"metadata":{"id":"ndcLYJUyTskU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_tokenizer(files, vocab_size, min_freq, max_len, save_path):\n","    tokenizer = ByteLevelBPETokenizer() \n","    tokenizer.train(files=files, vocab_size=vocab_size, min_frequency=min_freq, special_tokens=[\n","    \"<s>\",\n","    \"<pad>\",\n","    \"</s>\",\n","    \"<unk>\",\n","    \"<mask>\",\n","    ])\n","    tokenizer.save_model(save_path)\n","    tokenizer = ByteLevelBPETokenizer(save_path+\"vocab.json\", save_path+\"merges.txt\", )\n","    tokenizer._tokenizer.post_processor = BertProcessing(\n","        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n","    )\n","    tokenizer.enable_truncation(max_length=max_len)\n","\n","    tokenizer.save(save_path+\"tokenizer.json\")"],"metadata":{"id":"a7o3pgijQBya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LegalDataset(Dataset):\n","  def __init__(self, text):\n","    self.encodings = text\n","\n","  def __len__(self):\n","    return len(self.encodings)\n","\n","  def __getitem__(self, index):\n","    item = {\"input_ids\": torch.tensor(self.encodings.iloc[index])}\n","    return item\n","\n","\n","def process_text(filename, name, map_tokenize, encoding):\n","    print(\"Opening file...\")\n","    file = open(filename, \"r\", encoding=encoding)\n","    text = file.readlines() # list\n","    file.close()\n","    text = pd.Series(text)\n","    tqdm.pandas(desc=\"Tokenizing\")\n","    text = text.progress_map(map_tokenize)\n","    dataset = LegalDataset(text)\n","    text = None\n","    occ = filename.rfind(\"/\") + 1\n","    path = filename[:occ]\n","    torch.save(dataset, path+name+\".pt\")\n","    return path+name+\".pt\""],"metadata":{"id":"rheh_N40QiAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    tokenizer='/content/model/tokenizer/',\n","    files='/content/text/all_in_one.txt',\n","    encoding='utf8',\n","    vocab_size=32000,\n","    min_freq=2,\n","    sequence_len=512,\n","    model_path='/content/model',\n","    dataset='/content/text/new_dataset.pt',\n","    dataset_name='new_dataset',\n","    mlm_prob=0.15,\n","    hidden_layers=12,\n","    hidden_size=768,\n","    attention_heads=12,\n","    epochs=40,\n","    batch_size=8,\n","    max_steps=0,\n","    lrate=1e-4,\n","    b1=0.9,\n","    b2=0.99,\n","    wdecay=0.01,\n","    scheduler='linear',\n","    warmup_steps=10_000,\n","    checkpoint='/content/checkpoints',\n","    save_steps=10_000,\n","    save_limit=5,\n","    resume='/content/checkpoints/checkpoint-480000'\n",")"],"metadata":{"id":"-zDrHjAfS-Ds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create directories\n","try:\n","    os.mkdir(args.model_path)\n","except OSError as err: \n","    pass"],"metadata":{"id":"y0c4jWRxWwND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Tokenizer\n","tokenizer_path = None\n","if args.tokenizer==None :\n","    print(\"Creating new tokenizer\")\n","    tokenizer_path = args.model_path+\"/tokenizer/\"\n","    try:\n","        os.mkdir(tokenizer_path)\n","    except OSError as err:\n","        print()\n","    create_tokenizer(args.files, args.vocab_size, args.min_freq, args.sequence_len, tokenizer_path)\n","else:\n","    tokenizer_path = args.tokenizer\n","    print(\"Using tokenizer from\", tokenizer_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTyfg6tvYs47","executionInfo":{"status":"ok","timestamp":1648707847308,"user_tz":-180,"elapsed":262,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}},"outputId":"c716b97a-bd04-4b8d-d3ec-8d2c0f883bc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using tokenizer from /content/model/tokenizer/\n"]}]},{"cell_type":"code","source":["# Load Tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(tokenizer_path, max_len=args.sequence_len)"],"metadata":{"id":"7yz9zwuFY3xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create lamda tokenizing function\n","def map_tokenize(text):\n","    return tokenizer.encode(text, max_length=args.sequence_len, truncation=True)"],"metadata":{"id":"QNbnRQLrchTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process Text\n","dataset_path = None\n","if args.dataset == None :\n","    print(\"Processing text\")\n","    dataset_path = process_text(args.files, args.dataset_name, map_tokenize, args.encoding)\n","else:\n","    dataset_path = args.dataset\n","    print(\"Using dataset from\", dataset_path)\n","\n","# Load Dataset\n","dataset = torch.load(dataset_path) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FGSXmv_ci9r","executionInfo":{"status":"ok","timestamp":1648707864811,"user_tz":-180,"elapsed":12049,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}},"outputId":"710b4819-7560-4b3a-ee8c-30c7deb54de7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using dataset from /content/text/new_dataset.pt\n"]}]},{"cell_type":"code","source":["# Create Masked Language Model\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=args.mlm_prob\n",")\n","data_collator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jK21ZGzwcnmT","executionInfo":{"status":"ok","timestamp":1648707869646,"user_tz":-180,"elapsed":361,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}},"outputId":"1ee4c5f8-3f02-4b1e-d6f9-0cafbf772b7c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='/content/model/tokenizer/', vocab_size=32000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)}), mlm=True, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["config = BertConfig(\n","    vocab_size=args.vocab_size,\n","    max_position_embeddings=args.sequence_len,\n","    num_hidden_layers=args.hidden_layers,    #L\n","    hidden_size=args.hidden_size,        #H\n","    num_attention_heads=args.attention_heads,  #A\n","    type_vocab_size=1,\n",")\n","\n","\n","model = BertForMaskedLM(config=config)"],"metadata":{"id":"F1uRaWXFeYeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=args.checkpoint,\n","    overwrite_output_dir=True,\n","    num_train_epochs=args.epochs,\n","    per_device_train_batch_size=args.batch_size,\n","    save_steps=args.save_steps,\n","    save_total_limit=args.save_limit,\n","    prediction_loss_only=True,\n","    max_steps=args.max_steps,\n","    learning_rate=args.lrate,\n","    adam_beta1=args.b1,\n","    adam_beta2=args.b2,\n","    weight_decay=args.wdecay,\n","    lr_scheduler_type=args.scheduler,\n","    warmup_steps=args.warmup_steps,\n",")"],"metadata":{"id":"n3Q-TjiFegiv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset\n",")"],"metadata":{"id":"2d3PkvUdesKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train\n","if args.resume == None :\n","    print(\"Pre-training BERT model\")\n","    trainer.train()\n","else:\n","    print(\"Pre-training BERT model from checkpoint\", args.resume)\n","    trainer.train(resume_from_checkpoint=args.resume)\n","\n","# Save model\n","print(\"Saving model at\", args.model_path)\n","trainer.save_model(args.model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e559b60acbf344a2a9463a523017a6cf","502a141d3fb54ea28fc7b07c46e649e3","17f33352d96044f0a5112b4dacc3d6f1","d948858390ec4160be053b537592b00e","81a00a7bc12b410390fc6e9133296515","f559c1fe5ddf46cd9564b083b640b9ec","a7af71da98db4379a667276ec435162e","c66fb6bc56b84cb3959a6b5bb5549668","a1c845597af746e0a6a9b5f195857912","6a441a6bdd4042a0b8b192bc394446b8","0cf3e2824e454d49829c508931c2e22d"]},"id":"0nDlUEwoetu0","outputId":"056da0be-5ef3-44c1-bf81-1bb116becb8e","executionInfo":{"status":"ok","timestamp":1648748408612,"user_tz":-180,"elapsed":40441945,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading model from /content/checkpoints/checkpoint-480000).\n"]},{"output_type":"stream","name":"stdout","text":["Pre-training BERT model from checkpoint /content/checkpoints/checkpoint-480000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 214315\n","  Num Epochs = 40\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 535800\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 35\n","  Continuing training from global step 480000\n","  Will skip the first 35 epochs then the first 11175 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e559b60acbf344a2a9463a523017a6cf","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/11175 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='535800' max='535800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [535800/535800 11:12:59, Epoch 40/40]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>480500</td>\n","      <td>1.968100</td>\n","    </tr>\n","    <tr>\n","      <td>481000</td>\n","      <td>1.955000</td>\n","    </tr>\n","    <tr>\n","      <td>481500</td>\n","      <td>1.973800</td>\n","    </tr>\n","    <tr>\n","      <td>482000</td>\n","      <td>1.964200</td>\n","    </tr>\n","    <tr>\n","      <td>482500</td>\n","      <td>1.948000</td>\n","    </tr>\n","    <tr>\n","      <td>483000</td>\n","      <td>1.958300</td>\n","    </tr>\n","    <tr>\n","      <td>483500</td>\n","      <td>1.955000</td>\n","    </tr>\n","    <tr>\n","      <td>484000</td>\n","      <td>1.943600</td>\n","    </tr>\n","    <tr>\n","      <td>484500</td>\n","      <td>1.960200</td>\n","    </tr>\n","    <tr>\n","      <td>485000</td>\n","      <td>1.950400</td>\n","    </tr>\n","    <tr>\n","      <td>485500</td>\n","      <td>1.966000</td>\n","    </tr>\n","    <tr>\n","      <td>486000</td>\n","      <td>1.965800</td>\n","    </tr>\n","    <tr>\n","      <td>486500</td>\n","      <td>1.950100</td>\n","    </tr>\n","    <tr>\n","      <td>487000</td>\n","      <td>1.952100</td>\n","    </tr>\n","    <tr>\n","      <td>487500</td>\n","      <td>1.949100</td>\n","    </tr>\n","    <tr>\n","      <td>488000</td>\n","      <td>1.951700</td>\n","    </tr>\n","    <tr>\n","      <td>488500</td>\n","      <td>1.947700</td>\n","    </tr>\n","    <tr>\n","      <td>489000</td>\n","      <td>1.940500</td>\n","    </tr>\n","    <tr>\n","      <td>489500</td>\n","      <td>1.930400</td>\n","    </tr>\n","    <tr>\n","      <td>490000</td>\n","      <td>1.958900</td>\n","    </tr>\n","    <tr>\n","      <td>490500</td>\n","      <td>1.963000</td>\n","    </tr>\n","    <tr>\n","      <td>491000</td>\n","      <td>1.956500</td>\n","    </tr>\n","    <tr>\n","      <td>491500</td>\n","      <td>1.955000</td>\n","    </tr>\n","    <tr>\n","      <td>492000</td>\n","      <td>1.953500</td>\n","    </tr>\n","    <tr>\n","      <td>492500</td>\n","      <td>1.972100</td>\n","    </tr>\n","    <tr>\n","      <td>493000</td>\n","      <td>1.961000</td>\n","    </tr>\n","    <tr>\n","      <td>493500</td>\n","      <td>1.952200</td>\n","    </tr>\n","    <tr>\n","      <td>494000</td>\n","      <td>1.966800</td>\n","    </tr>\n","    <tr>\n","      <td>494500</td>\n","      <td>1.934000</td>\n","    </tr>\n","    <tr>\n","      <td>495000</td>\n","      <td>1.948000</td>\n","    </tr>\n","    <tr>\n","      <td>495500</td>\n","      <td>1.968400</td>\n","    </tr>\n","    <tr>\n","      <td>496000</td>\n","      <td>1.930000</td>\n","    </tr>\n","    <tr>\n","      <td>496500</td>\n","      <td>1.930800</td>\n","    </tr>\n","    <tr>\n","      <td>497000</td>\n","      <td>1.935800</td>\n","    </tr>\n","    <tr>\n","      <td>497500</td>\n","      <td>1.931000</td>\n","    </tr>\n","    <tr>\n","      <td>498000</td>\n","      <td>1.923800</td>\n","    </tr>\n","    <tr>\n","      <td>498500</td>\n","      <td>1.932300</td>\n","    </tr>\n","    <tr>\n","      <td>499000</td>\n","      <td>1.957300</td>\n","    </tr>\n","    <tr>\n","      <td>499500</td>\n","      <td>1.925400</td>\n","    </tr>\n","    <tr>\n","      <td>500000</td>\n","      <td>1.948800</td>\n","    </tr>\n","    <tr>\n","      <td>500500</td>\n","      <td>1.918400</td>\n","    </tr>\n","    <tr>\n","      <td>501000</td>\n","      <td>1.952600</td>\n","    </tr>\n","    <tr>\n","      <td>501500</td>\n","      <td>1.949800</td>\n","    </tr>\n","    <tr>\n","      <td>502000</td>\n","      <td>1.931800</td>\n","    </tr>\n","    <tr>\n","      <td>502500</td>\n","      <td>1.943000</td>\n","    </tr>\n","    <tr>\n","      <td>503000</td>\n","      <td>1.939800</td>\n","    </tr>\n","    <tr>\n","      <td>503500</td>\n","      <td>1.953400</td>\n","    </tr>\n","    <tr>\n","      <td>504000</td>\n","      <td>1.930800</td>\n","    </tr>\n","    <tr>\n","      <td>504500</td>\n","      <td>1.921300</td>\n","    </tr>\n","    <tr>\n","      <td>505000</td>\n","      <td>1.930300</td>\n","    </tr>\n","    <tr>\n","      <td>505500</td>\n","      <td>1.927000</td>\n","    </tr>\n","    <tr>\n","      <td>506000</td>\n","      <td>1.928100</td>\n","    </tr>\n","    <tr>\n","      <td>506500</td>\n","      <td>1.911700</td>\n","    </tr>\n","    <tr>\n","      <td>507000</td>\n","      <td>1.938000</td>\n","    </tr>\n","    <tr>\n","      <td>507500</td>\n","      <td>1.939900</td>\n","    </tr>\n","    <tr>\n","      <td>508000</td>\n","      <td>1.938900</td>\n","    </tr>\n","    <tr>\n","      <td>508500</td>\n","      <td>1.937300</td>\n","    </tr>\n","    <tr>\n","      <td>509000</td>\n","      <td>1.931500</td>\n","    </tr>\n","    <tr>\n","      <td>509500</td>\n","      <td>1.931300</td>\n","    </tr>\n","    <tr>\n","      <td>510000</td>\n","      <td>1.932700</td>\n","    </tr>\n","    <tr>\n","      <td>510500</td>\n","      <td>1.947400</td>\n","    </tr>\n","    <tr>\n","      <td>511000</td>\n","      <td>1.932700</td>\n","    </tr>\n","    <tr>\n","      <td>511500</td>\n","      <td>1.909300</td>\n","    </tr>\n","    <tr>\n","      <td>512000</td>\n","      <td>1.922000</td>\n","    </tr>\n","    <tr>\n","      <td>512500</td>\n","      <td>1.924800</td>\n","    </tr>\n","    <tr>\n","      <td>513000</td>\n","      <td>1.906800</td>\n","    </tr>\n","    <tr>\n","      <td>513500</td>\n","      <td>1.922400</td>\n","    </tr>\n","    <tr>\n","      <td>514000</td>\n","      <td>1.913400</td>\n","    </tr>\n","    <tr>\n","      <td>514500</td>\n","      <td>1.917800</td>\n","    </tr>\n","    <tr>\n","      <td>515000</td>\n","      <td>1.924200</td>\n","    </tr>\n","    <tr>\n","      <td>515500</td>\n","      <td>1.914300</td>\n","    </tr>\n","    <tr>\n","      <td>516000</td>\n","      <td>1.914300</td>\n","    </tr>\n","    <tr>\n","      <td>516500</td>\n","      <td>1.930000</td>\n","    </tr>\n","    <tr>\n","      <td>517000</td>\n","      <td>1.913700</td>\n","    </tr>\n","    <tr>\n","      <td>517500</td>\n","      <td>1.931400</td>\n","    </tr>\n","    <tr>\n","      <td>518000</td>\n","      <td>1.935700</td>\n","    </tr>\n","    <tr>\n","      <td>518500</td>\n","      <td>1.928600</td>\n","    </tr>\n","    <tr>\n","      <td>519000</td>\n","      <td>1.910800</td>\n","    </tr>\n","    <tr>\n","      <td>519500</td>\n","      <td>1.927600</td>\n","    </tr>\n","    <tr>\n","      <td>520000</td>\n","      <td>1.930500</td>\n","    </tr>\n","    <tr>\n","      <td>520500</td>\n","      <td>1.917800</td>\n","    </tr>\n","    <tr>\n","      <td>521000</td>\n","      <td>1.936200</td>\n","    </tr>\n","    <tr>\n","      <td>521500</td>\n","      <td>1.931100</td>\n","    </tr>\n","    <tr>\n","      <td>522000</td>\n","      <td>1.904800</td>\n","    </tr>\n","    <tr>\n","      <td>522500</td>\n","      <td>1.922600</td>\n","    </tr>\n","    <tr>\n","      <td>523000</td>\n","      <td>1.904400</td>\n","    </tr>\n","    <tr>\n","      <td>523500</td>\n","      <td>1.929800</td>\n","    </tr>\n","    <tr>\n","      <td>524000</td>\n","      <td>1.884000</td>\n","    </tr>\n","    <tr>\n","      <td>524500</td>\n","      <td>1.888200</td>\n","    </tr>\n","    <tr>\n","      <td>525000</td>\n","      <td>1.927900</td>\n","    </tr>\n","    <tr>\n","      <td>525500</td>\n","      <td>1.904600</td>\n","    </tr>\n","    <tr>\n","      <td>526000</td>\n","      <td>1.907300</td>\n","    </tr>\n","    <tr>\n","      <td>526500</td>\n","      <td>1.900000</td>\n","    </tr>\n","    <tr>\n","      <td>527000</td>\n","      <td>1.894700</td>\n","    </tr>\n","    <tr>\n","      <td>527500</td>\n","      <td>1.906400</td>\n","    </tr>\n","    <tr>\n","      <td>528000</td>\n","      <td>1.922600</td>\n","    </tr>\n","    <tr>\n","      <td>528500</td>\n","      <td>1.916700</td>\n","    </tr>\n","    <tr>\n","      <td>529000</td>\n","      <td>1.912700</td>\n","    </tr>\n","    <tr>\n","      <td>529500</td>\n","      <td>1.917800</td>\n","    </tr>\n","    <tr>\n","      <td>530000</td>\n","      <td>1.921800</td>\n","    </tr>\n","    <tr>\n","      <td>530500</td>\n","      <td>1.938900</td>\n","    </tr>\n","    <tr>\n","      <td>531000</td>\n","      <td>1.907100</td>\n","    </tr>\n","    <tr>\n","      <td>531500</td>\n","      <td>1.900100</td>\n","    </tr>\n","    <tr>\n","      <td>532000</td>\n","      <td>1.923000</td>\n","    </tr>\n","    <tr>\n","      <td>532500</td>\n","      <td>1.909900</td>\n","    </tr>\n","    <tr>\n","      <td>533000</td>\n","      <td>1.899500</td>\n","    </tr>\n","    <tr>\n","      <td>533500</td>\n","      <td>1.934900</td>\n","    </tr>\n","    <tr>\n","      <td>534000</td>\n","      <td>1.915300</td>\n","    </tr>\n","    <tr>\n","      <td>534500</td>\n","      <td>1.929900</td>\n","    </tr>\n","    <tr>\n","      <td>535000</td>\n","      <td>1.903600</td>\n","    </tr>\n","    <tr>\n","      <td>535500</td>\n","      <td>1.914100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/checkpoints/checkpoint-490000\n","Configuration saved in /content/checkpoints/checkpoint-490000/config.json\n","Model weights saved in /content/checkpoints/checkpoint-490000/pytorch_model.bin\n","Deleting older checkpoint [/content/checkpoints/checkpoint-440000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Saving model checkpoint to /content/checkpoints/checkpoint-500000\n","Configuration saved in /content/checkpoints/checkpoint-500000/config.json\n","Model weights saved in /content/checkpoints/checkpoint-500000/pytorch_model.bin\n","Deleting older checkpoint [/content/checkpoints/checkpoint-450000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Saving model checkpoint to /content/checkpoints/checkpoint-510000\n","Configuration saved in /content/checkpoints/checkpoint-510000/config.json\n","Model weights saved in /content/checkpoints/checkpoint-510000/pytorch_model.bin\n","Deleting older checkpoint [/content/checkpoints/checkpoint-460000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Saving model checkpoint to /content/checkpoints/checkpoint-520000\n","Configuration saved in /content/checkpoints/checkpoint-520000/config.json\n","Model weights saved in /content/checkpoints/checkpoint-520000/pytorch_model.bin\n","Deleting older checkpoint [/content/checkpoints/checkpoint-470000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Saving model checkpoint to /content/checkpoints/checkpoint-530000\n","Configuration saved in /content/checkpoints/checkpoint-530000/config.json\n","Model weights saved in /content/checkpoints/checkpoint-530000/pytorch_model.bin\n","Deleting older checkpoint [/content/checkpoints/checkpoint-480000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to /content/model\n","Configuration saved in /content/model/config.json\n"]},{"output_type":"stream","name":"stdout","text":["Saving model at /content/model\n"]},{"output_type":"stream","name":"stderr","text":["Model weights saved in /content/model/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["from google.cloud import storage\n","\n","client = storage.Client()\n","input_bucket = client.get_bucket('oceanic-ner-model')\n","\n","input_bucket.blob('bert/pytorch_model.bin').upload_from_filename('/content/model/pytorch_model.bin')\n","input_bucket.blob('bert/training_args.bin').upload_from_filename('/content/model/training_args.bin')\n","input_bucket.blob('bert/config.json').upload_from_filename('/content/model/config.json')\n","\n","input_bucket.blob('bert/tokenizer/merges.txt').upload_from_filename('/content/model/tokenizer/merges.json')\n","input_bucket.blob('bert/tokenizer/tokenizer.json').upload_from_filename('/content/model/tokenizer/tokenizer.json')\n","input_bucket.blob('bert/tokenizer/vocab.json').upload_from_filename('/content/model/tokenizer/vocab.json')"],"metadata":{"id":"4j2MiN6ThMZf","executionInfo":{"status":"ok","timestamp":1649519791792,"user_tz":-180,"elapsed":704,"user":{"displayName":"Tony Zaitoun","userId":"11427402115843832412"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"eOX5D-YC_Ti7"},"execution_count":null,"outputs":[]}]}